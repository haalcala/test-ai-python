{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f1594c-f253-44de-97ed-d88e33564535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load the model and tokenizer\n",
    "\n",
    "model = load_model('nextword1.h5')\n",
    "tokenizer = pickle.load(open('tokenizer1.pkl', 'rb'))\n",
    "\n",
    "words = np.array(list(tokenizer.word_index.keys()))\n",
    "words_indexes = np.array(list(tokenizer.word_index.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "373910ef-d25a-41b6-87a5-74498f7dfab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_Next_Words(model, tokenizer, text):\n",
    "    \"\"\"\n",
    "        In this function we are using the tokenizer and models trained\n",
    "        and we are creating the sequence of the text entered and then\n",
    "        using our model to predict and return the the predicted word.\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(3):\n",
    "        sequence = tokenizer.texts_to_sequences([text])[0]\n",
    "#         print(f\"1111 sequence: {sequence} {len(sequence)}\")\n",
    "        sequence = np.array(sequence)\n",
    "#         print(f\"2222 sequence: {sequence} {len(sequence)}\")\n",
    "\n",
    "#         preds = model.predict_classes(sequence)\n",
    "        predict_x=model.predict(sequence)\n",
    "#         print(f\"predict_x: {predict_x} {len(predict_x[0][:-1])}\")\n",
    "#         classes_x=np.argmax(predict_x,axis=1)\n",
    "        predict_x_0 = predict_x[0][1:]\n",
    "#         for x in predict_x_0:\n",
    "#             print(str(x), end=\" \")\n",
    "        classes_x = predict_x_0[predict_x_0 > .01]\n",
    "    \n",
    "#         print(f\"classes_x: {classes_x}\")\n",
    "        \n",
    "        preds = classes_x\n",
    "#         print(f\"preds: {preds}\")\n",
    "        predicted_word = words[predict_x_0 > .001]\n",
    "        \n",
    "#         for key, value in tokenizer.word_index.items():\n",
    "#             if value == preds:\n",
    "#                 predicted_word = key\n",
    "#                 break\n",
    "        \n",
    "#         print(f\"predicted_word: {predicted_word}\")\n",
    "        return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a7b45b4-c871-4a30-8a31-7a2119fb4942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your line:  to\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: to\n",
      "predicted: ['the' 'and' 'his' 'it' 'in' 'a' 'gregor' 'him' 'her' 'but' 'they' 'all'\n",
      " 'be' 'have' \"gregor's\" 'so' 'this' 'himself' 'even' 'one' 'their' 'what'\n",
      " 'them' 'you' 'just' 'any' 'do' 'get' 'go' 'some' 'see' 'much' 'where'\n",
      " 'open' 'which' 'come' 'an' 'bed' 'everything' 'let' 'being' 'work'\n",
      " 'three' 'make' 'mr' 'look' 'slowly' 'side' 'grete' 'think' 'lay' 'feel'\n",
      " 'its' 'always' 'say' 'herself' 'me' 'know' 'each' 'your' 'move' 'help'\n",
      " 'immediately' 'behind' 'sleep' 'put' 'called' 'anything' 'face' 'close'\n",
      " 'hear' 'leave' 'take' 'set' 'want' 'give' 'keep' 'stay' 'us' 'eat'\n",
      " 'whether' 'themselves' 'turn' 'seven' 'use' 'notice' 'fall' 'bring'\n",
      " 'speak' 'stand' 'both' 'carry' 'calm' 'actually' 'crawl' 'forget'\n",
      " 'sleeping' 'god' 'try' 'tell' 'find' 'listen' 'hold' 'earn' 'cut'\n",
      " 'overcome' 'pay' 'quietly' 'rush' 'throw' 'show' 'wait' 'start' 'spare'\n",
      " 'stop' 'send' 'sit' 'live' 'catch' 'remove' 'push' 'control' 'call'\n",
      " 'worry' 'our' 'save' 'talk' 'drive' 'bear' 'breathe' 'fetch' 'lift'\n",
      " 'avoid' 'report' 'knock' 'ask' 'raise' 'giving' 'waste' 'learn' 'suffer'\n",
      " 'remember' 'provide' 'persuade' 'enter' 'remain' 'regret' 'test'\n",
      " 'continue' 'pull' 'insist' 'admit' 'chase' 'death' 'mean' 'clean' 'play'\n",
      " 'curse' 'explain' 'blow' 'bend' 'imagine' 'sacrifice' 'remind' 'cry'\n",
      " 'appear' 'forgetting' 'climb' 'grasp' 'arrange' 'draw' 'hurt' 'wake'\n",
      " 'exchange' 'cheek' 'begin' 'cover' 'slide' 'hell' 'copy' 'decide'\n",
      " 'desperate' 'offer' 'investigate' 'concede' 'forgive' 'intercede'\n",
      " 'recover' 'gossip' 'defend' 'reach' 'hinder' 're' 'impose' 'starve'\n",
      " 'reduce' 'enable' 'maintain' 'stare' 'pretend' 'bite' 'hide' 'flee'\n",
      " 'entertain' 'choose' 'cope' 'transform' 'prevent' 'attract' 'assure'\n",
      " 'spin' 'muster' 'bombard' 'drag' 'swallow' 'serve' 'transport'\n",
      " 'withstand' 'discard' 'enjoy' 'count' 'establish' 'perform' 'hiss'\n",
      " 'block' 'gain' 'proceed' 'cough' 'protect' 'distract' 'tickle' 'yank'\n",
      " 'confirm' 'prove' 'mistrust']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your line:  .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending The Program.....\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    We are testing our model and we will run the model\n",
    "    until the user decides to stop the script.\n",
    "    While the script is running we try and check if \n",
    "    the prediction can be made on the text. If no\n",
    "    prediction can be made we just continue.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# text1 = \"at the dull\"\n",
    "# text2 = \"collection of textile\"\n",
    "# text3 = \"what a strenuous\"\n",
    "# text4 = \".\"\n",
    "\n",
    "while(True):\n",
    "\n",
    "    text = input(\"Enter your line: \")\n",
    "    \n",
    "    if text == \".\":\n",
    "        print(\"Ending The Program.....\")\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            text = text.split(\" \")\n",
    "            text = text[-1]\n",
    "\n",
    "            text = ''.join(text)\n",
    "            \n",
    "            print(f\"text: {text}\")\n",
    "            predicted = Predict_Next_Words(model, tokenizer, text)\n",
    "            \n",
    "            print(f\"predicted: {predicted}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a95c55a3-1ed9-4664-9265-6e388663114b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    3, ..., 2614, 2615, 2616])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f19c5ad8-4171-4efa-ae42-52615cd0bb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2616"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7d2be3a8-f03d-4bbc-bc1f-3f2477429ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['the', 'to', 'and', ..., 'agreed', 'confirmation', 'destination'],\n",
       "      dtype='<U17')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db71032d-330c-4282-a1b6-0363551213cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2616"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df8c7fce-6189-44ff-92e6-559655a1e72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1 , 0.5 , 1.  , 0.05, 0.8 , 2.  ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([.1, .5, 1, .05, .8, 2])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55dba771-85b5-4731-892f-8603b12f24d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1. ,  5. , 10. ,  0.5,  8. , 20. ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14c9898f-f8bd-4dd2-b779-0a6ab804d368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-3:][a[-3:] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14f3f3f0-9568-4ce4-a320-10f276875e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4978440b-b3e3-4273-9f1f-3f2579feb78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[np.argmax(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ac9d68a-6c12-4105-8956-6e74959300f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False,  True,  True])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a > .5\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "344ee797-ab41-4e2d-b261-18003c3969ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0.8, 2. ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a >= .8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d93aebf4-6bf3-4880-838d-0590e87065c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "either both or neither of x and y should be given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-1ae306dca23e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: either both or neither of x and y should be given"
     ]
    }
   ],
   "source": [
    "np.where(a >= .8, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdbd4380-2277-4b97-ae4d-216b3dfc9b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2616"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a4f327e-b501-462a-9c1d-a4562399b5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    3, ..., 2614, 2615, 2616])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array(list(tokenizer.word_index.values()))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8bbc6c0-a298-4dfb-8636-5e4f4e14b628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = c > 100\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d41accb4-e36f-4e86-a7d9-1a2407c4de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.array(list(tokenizer.word_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d618840-e33c-4078-a686-13d1d942c634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['went', 'come', 'away', ..., 'agreed', 'confirmation',\n",
       "       'destination'], dtype='<U17')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d983919-2a77-485f-87d8-11e31a81c0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2616"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f0765b22-3ef6-4c2d-b9c5-70b8c05408bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2616"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57f49e7a-434e-4cb6-99b0-9c29cb012d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2616"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b66baff-f097-48e4-adbe-0da99af7462a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
